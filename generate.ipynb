{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"generate.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1YQXxsRA_Et8LUEWM2sUzqK4dzrd7-3OR","authorship_tag":"ABX9TyPcSZlmLHmB59xNeJdAxmKh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"6bce77d8fcbc4b59b1c4b5461a7003a9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2e5c9b64d84f40038f1e0d37a8ef9c41","IPY_MODEL_666ce207284148beb705a69e6f7d3326","IPY_MODEL_bd45b415ab184efa8f6c512af231007b"],"layout":"IPY_MODEL_925bc13e37bd4f719f52c62a2706e74a"}},"2e5c9b64d84f40038f1e0d37a8ef9c41":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5227f05257fe4d8ca13c034eac6a871c","placeholder":"​","style":"IPY_MODEL_9ea9e526519d434a90e11b943f2b981c","value":"100%"}},"666ce207284148beb705a69e6f7d3326":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad943d1bed674f10babe5ebf215ceb2a","max":40456,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d7d0fff493a645fd8a8cc7d502e6ca9b","value":40456}},"bd45b415ab184efa8f6c512af231007b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1079cad20634ab3802f06a0f56d6dd9","placeholder":"​","style":"IPY_MODEL_578c547d57a144999a25a75484103457","value":" 40456/40456 [00:00&lt;00:00, 339013.14it/s]"}},"925bc13e37bd4f719f52c62a2706e74a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5227f05257fe4d8ca13c034eac6a871c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ea9e526519d434a90e11b943f2b981c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad943d1bed674f10babe5ebf215ceb2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d7d0fff493a645fd8a8cc7d502e6ca9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c1079cad20634ab3802f06a0f56d6dd9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"578c547d57a144999a25a75484103457":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Import Modules"],"metadata":{"id":"_eaG1Bz5u3nw"}},{"cell_type":"code","source":["# Standard libraries\n","import os\n","import pickle\n","import numpy as np\n","from tqdm.notebook import tqdm\n","import re\n","from zipfile import ZipFile, ZIP_DEFLATED # for zipping of dataset because its too large\n","\n","# ML/Deep Learning frameworks\n","from tensorflow import keras\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","from keras.models import Model\n","from keras.preprocessing.image import load_img, img_to_array\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical, plot_model"],"metadata":{"id":"sFThA51Du63C","executionInfo":{"status":"ok","timestamp":1657131028989,"user_tz":-480,"elapsed":309,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Data directory"],"metadata":{"id":"Z06n5uCmvffE"}},{"cell_type":"code","source":["DATA_DIRECTORY = './drive/Othercomputers/My MacBook Air/imageCaptionGenerator/dataset/'\n","WORKING_DIRECTORY = './drive/Othercomputers/My MacBook Air/imageCaptionGenerator/'"],"metadata":{"id":"dtnDv8GKvfww","executionInfo":{"status":"ok","timestamp":1657131031306,"user_tz":-480,"elapsed":321,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Extract image features using pre-trained VGG16 model and store in a pickle file\n","**NOTE**: Only run this if you do not have features.pkl **and** features.pkl.zip file\n","\n","[add remark on image dataset]"],"metadata":{"id":"Ydh36vU_vnJ7"}},{"cell_type":"code","source":["# ## load vgg16 model\n","# model = VGG16() \n","# ## exclude last layer\n","# model = Model(inputs=model.inputs, outputs=model.layers[-2].output) \n","# # print(model.summary())\n","# \n","# ## extract features from image\n","# features = {}\n","# directory = os.path.join(DATA_DIRECTORY, 'Images')\n","# for img_name in tqdm(os.listdir(directory)):\n","#   ## load image from file\n","#   img_file = directory + '/' + img_name\n","#   image = load_img(img_file, target_size=(224,224))\n","#   ## reshape image to numpy array\n","#   image = img_to_array(image)\n","#   ## reshape data for model (VGG16 takes in 4d array)\n","#   image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","#   ## preprocess image for customized to vgg model\n","#   image = preprocess_input(image)\n","#   ## extract features\n","#   feature = model.predict(image, verbose=0) # toggle off any other display\n","#   ## get image ID\n","#   image_id = img_name.split('.')[0] # first index after splitting image name \n","#   ## store features\n","#   features[image_id] = feature\n","\n","\n","# ## Store features in pickle to avoid re-downloading\n","# pickle.dump(features, open(os.path.join(WORKING_DIRECTORY, 'features.pkl'), 'wb')) # write-binary"],"metadata":{"id":"eO48Q1S3vvRc","executionInfo":{"status":"ok","timestamp":1657131040805,"user_tz":-480,"elapsed":325,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Load features (of images) pickle file\n","**Note**: This should only be done if using raw file"],"metadata":{"id":"dbmqyNhMljYL"}},{"cell_type":"code","source":["# with open(os.path.join(WORKING_DIRECTORY, 'features.pkl'), 'rb') as f:\n","#   features = pickle.load(f)"],"metadata":{"id":"C9Bl0dMTllv_","executionInfo":{"status":"ok","timestamp":1657131043582,"user_tz":-480,"elapsed":297,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Uncomment to mount drive to use existing data stored locally"],"metadata":{"id":"hR0RyyBIpTix"}},{"cell_type":"code","source":["# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"id":"Cp6txObDpfa7","executionInfo":{"status":"ok","timestamp":1657131044538,"user_tz":-480,"elapsed":4,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["## [**DEFAULT**] Unzip and load features pickle file"],"metadata":{"id":"UDJsmhKQplv3"}},{"cell_type":"code","source":["with ZipFile(os.path.join(WORKING_DIRECTORY, 'features.pkl.zip'), 'r') as zipObj:\n","   ## Extract all the contents of zip file into current directory\n","   print(\"Note that this was done in google colab, current directory is /content which is where the features.pkl file will be located.\")\n","   zipObj.extractall('./') \n","\n","with open('./features.pkl', 'rb') as f:\n","  features = pickle.load(f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"chvCe_qdpl85","executionInfo":{"status":"ok","timestamp":1657131048798,"user_tz":-480,"elapsed":2839,"user":{"displayName":"Andre","userId":"17346316937089295447"}},"outputId":"1172e33d-9525-4b76-8186-1cba0cd349e8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Note that this was done in google colab, current directory is /content which is where the features.pkl file will be located.\n"]}]},{"cell_type":"markdown","source":["##  Then load captions file"],"metadata":{"id":"cuj8XXv3mO5Q"}},{"cell_type":"code","source":["with open(os.path.join(DATA_DIRECTORY, 'captions.txt'), 'r') as f:\n","  next(f) # ignore first line in captions.txt\n","  captions = f.read()"],"metadata":{"id":"hHe9IUTzmPGR","executionInfo":{"status":"ok","timestamp":1657131049483,"user_tz":-480,"elapsed":687,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["## Map image to captions"],"metadata":{"id":"djpyOYL8mdlF"}},{"cell_type":"code","source":["mapping = {}\n","for line in tqdm(captions.split('\\n')):\n","  if len(line) < 2:\n","    continue\n","  ## split line by comma\n","  tokens = line.split(',')\n","  ## get id and caption\n","  image_id, caption = tokens[0].split('.')[0], ''.join(tokens[1:])\n","\n","  ## group captions for same images tgt\n","  if image_id not in mapping:\n","    mapping[image_id] = [caption]\n","  else:\n","    mapping[image_id].append(caption)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["6bce77d8fcbc4b59b1c4b5461a7003a9","2e5c9b64d84f40038f1e0d37a8ef9c41","666ce207284148beb705a69e6f7d3326","bd45b415ab184efa8f6c512af231007b","925bc13e37bd4f719f52c62a2706e74a","5227f05257fe4d8ca13c034eac6a871c","9ea9e526519d434a90e11b943f2b981c","ad943d1bed674f10babe5ebf215ceb2a","d7d0fff493a645fd8a8cc7d502e6ca9b","c1079cad20634ab3802f06a0f56d6dd9","578c547d57a144999a25a75484103457"]},"id":"drBN09cfmdw5","executionInfo":{"status":"ok","timestamp":1657131049483,"user_tz":-480,"elapsed":7,"user":{"displayName":"Andre","userId":"17346316937089295447"}},"outputId":"2d843137-c4f6-4593-a79d-c58ef2bf7d2e"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/40456 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bce77d8fcbc4b59b1c4b5461a7003a9"}},"metadata":{}}]},{"cell_type":"code","source":["# len(mapping) # just quick check of image length"],"metadata":{"id":"U_5FmLVGmmtN","executionInfo":{"status":"aborted","timestamp":1657130895474,"user_tz":-480,"elapsed":16,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Preprocess caption data"],"metadata":{"id":"9sYh9x0koatA"}},{"cell_type":"code","source":["START_TAG = '<start> '\n","END_TAG = ' <end>'\n","def clean(mapping):\n","  for key, captions in mapping.items():\n","    for i in range(len(captions)):\n","      caption = captions[i]\n","      ## convert to lowercase and remove trailing spaces\n","      caption = caption.lower().strip()\n","      ## remove special chars\n","      caption = re.sub(\"[^A-Za-z ]\", \"\", caption)\n","      ## remove additional white spaces between words\n","      caption = re.sub(\"[ +]\", \" \", caption)\n","      ## indicate start and end tag\n","      caption = START_TAG + caption + END_TAG\n","      ## update\n","      captions[i] = caption"],"metadata":{"id":"Ouv_EEXOoa5O","executionInfo":{"status":"ok","timestamp":1657131051232,"user_tz":-480,"elapsed":2,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Testing result of preprocessing [optional]"],"metadata":{"id":"jnoCDmpRolBL"}},{"cell_type":"code","source":["print(\"Preprocessed: \", mapping['109202756_b97fcdc62c'])\n","clean(mapping)\n","print(\"Processed: \", mapping['109202756_b97fcdc62c'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVf8fgcnolJO","executionInfo":{"status":"ok","timestamp":1657131052743,"user_tz":-480,"elapsed":508,"user":{"displayName":"Andre","userId":"17346316937089295447"}},"outputId":"fcaa6950-ee45-4bba-fc5f-d6de27d5271c"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessed:  ['A woman dressed in a blue jacket and blue jeans rides a brown horse near a frozen lake and snow-covered mountain .', 'A woman in a blue jacket rides a brown pony near water .', 'A woman rides a horse near a frozen lake in the wintertime .', 'A young blond woman sitting atop a brown draft horse in the snowy mountains .', 'Woman n blue jacket sits on daft horse near a frozen lake .']\n","Processed:  ['<start> a woman dressed in a blue jacket and blue jeans rides a brown horse near a frozen lake and snowcovered mountain  <end>', '<start> a woman in a blue jacket rides a brown pony near water  <end>', '<start> a woman rides a horse near a frozen lake in the wintertime  <end>', '<start> a young blond woman sitting atop a brown draft horse in the snowy mountains  <end>', '<start> woman n blue jacket sits on daft horse near a frozen lake  <end>']\n"]}]},{"cell_type":"markdown","source":["## Get all captions"],"metadata":{"id":"XtUY37Ow0Xd5"}},{"cell_type":"code","source":["all_captions = []\n","for key in mapping:\n","  for caption in mapping[key]:\n","    all_captions.append(caption)\n","print(len(all_captions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4qQjGTl0Xok","executionInfo":{"status":"ok","timestamp":1657131053361,"user_tz":-480,"elapsed":3,"user":{"displayName":"Andre","userId":"17346316937089295447"}},"outputId":"4a9d9549-f0df-4fda-9776-4398f54c087f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["40455\n"]}]},{"cell_type":"markdown","source":["## Tokenizing captions"],"metadata":{"id":"xEGROrvz00OA"}},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","## map knowledge of words to a unique number/id\n","tokenizer.fit_on_texts(all_captions)\n","vocab_size = len(tokenizer.word_index) + 1 # note index starts from 1\n"],"metadata":{"id":"zVUAJXf-00Yq","executionInfo":{"status":"ok","timestamp":1657131056688,"user_tz":-480,"elapsed":692,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Find longest length of caption"],"metadata":{"id":"lRmZ3MTf2qOp"}},{"cell_type":"code","source":["max_length_caption = max(len(caption.split()) for caption in all_captions)\n","max_length_caption"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Eb8QeKj-2qZ1","executionInfo":{"status":"ok","timestamp":1657131057850,"user_tz":-480,"elapsed":464,"user":{"displayName":"Andre","userId":"17346316937089295447"}},"outputId":"734cbbe2-bb84-4e00-f764-e4e959178e57"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["37"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","source":["## Split data into Train & Test set\n","Standard 9:1 ratio\n","\n","update: run more epochs?"],"metadata":{"id":"ce3H0SMu250j"}},{"cell_type":"code","source":["all_keys = list(mapping.keys())\n","split = int(len(all_keys) * 0.9)\n","train_data = all_keys[:split]\n","test_data = all_keys[split:]"],"metadata":{"id":"WM_Zfj2g26NR","executionInfo":{"status":"ok","timestamp":1657131059808,"user_tz":-480,"elapsed":345,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Data generator to get data in batches"],"metadata":{"id":"yafhli7gOHAU"}},{"cell_type":"code","source":["def data_generator(train_keys, img_to_captions_map, img_features, tokenizer, max_length_caption, vocab_size, batch_size):\n","  X1, X2, y = [], [], []\n","  curr = 0\n","  while True:\n","    for key in train_keys:\n","      curr += 1\n","      captions = img_to_captions_map[key]\n","      for caption in captions:\n","        encoded = tokenizer.texts_to_sequences([caption])[0] # note takes in a list\n","        ## iterative split into input and output for LSTM model\n","        for i in range(1, len(encoded)): # start from <start> tag onwards\n","          in_, out_ = encoded[:i], encoded[i]\n","          in_ = pad_sequences([in_], maxlen=max_length_caption)[0]\n","          # print(in_)\n","          # break\n","          out_ = to_categorical([out_], num_classes=vocab_size)[0]\n","\n","          X1.append(features[key][0])\n","          X2.append(in_)\n","          y.append(out_)\n","      if curr == batch_size:\n","        X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n","        yield [X1, X2], y\n","        X1, X2, y = [], [], []\n","        curr = 0"],"metadata":{"id":"WLyiBEZNOHHn","executionInfo":{"status":"ok","timestamp":1657131061141,"user_tz":-480,"elapsed":1,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["## CNN-LSTM Model"],"metadata":{"id":"F6YQ39LLbRLo"}},{"cell_type":"code","source":["\"\"\"Encoder\"\"\"\n","## image layer\n","inputs1 = keras.layers.Input(shape=(4096,))\n","img_layer = keras.layers.Dropout(0.4)(inputs1)\n","img_layer = keras.layers.Dense(256, activation=\"relu\")(img_layer)\n","## caption layer\n","inputs2 = keras.layers.Input(shape=(max_length_caption,))\n","cap_layer = keras.layers.Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n","cap_layer = keras.layers.Dropout(0.4)(cap_layer)\n","cap_layer = keras.layers.LSTM(256)(cap_layer)\n","\n","\"\"\"Decoder\"\"\"\n","decoder = keras.layers.add([img_layer, cap_layer])\n","decoder = keras.layers.Dense(256, activation=\"relu\")(decoder)\n","outputs = keras.layers.Dense(vocab_size, activation=\"softmax\")(decoder)\n","\n","model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n","model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n","\n","plot_model(model, sho)"],"metadata":{"id":"x_NbEWDnbRXU","executionInfo":{"status":"aborted","timestamp":1657130895475,"user_tz":-480,"elapsed":16,"user":{"displayName":"Andre","userId":"17346316937089295447"}}},"execution_count":null,"outputs":[]}]}